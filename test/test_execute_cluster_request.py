# coding: utf-8

"""
    Mixpeek API

    This is the Mixpeek API, providing access to various endpoints for data processing and retrieval.

    The version of the OpenAPI document: 0.81
    Contact: info@mixpeek.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from mixpeek.models.execute_cluster_request import ExecuteClusterRequest

class TestExecuteClusterRequest(unittest.TestCase):
    """ExecuteClusterRequest unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> ExecuteClusterRequest:
        """Test ExecuteClusterRequest
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `ExecuteClusterRequest`
        """
        model = ExecuteClusterRequest()
        if include_optional:
            return ExecuteClusterRequest(
                collection_ids = [
                    ''
                    ],
                config = mixpeek.models.clustering_config.ClusteringConfig(
                    algorithm = 'kmeans', 
                    algorithm_params = null, 
                    feature_vector = mixpeek.models.feature_vector_ref.FeatureVectorRef(
                        feature_address = mixpeek.models.feature_address.FeatureAddress(
                            scheme = 'mixpeek', 
                            extractor = '', 
                            version = '', 
                            output = '', ), ), 
                    additional_features = [
                        ''
                        ], 
                    normalize_features = True, 
                    dimensionality_reduction = null, 
                    hierarchical = True, 
                    max_hierarchy_depth = 56, 
                    llm_labeling = mixpeek.models.llm_labeling.LLMLabeling(
                        enabled = True, 
                        provider = 'openai', 
                        model_name = '', 
                        include_summary = True, 
                        include_keywords = True, 
                        max_samples_per_cluster = 56, 
                        custom_prompt = '', 
                        parameters = { }, ), 
                    batch_size = 56, 
                    parallelism = 56, 
                    sample_size = 56, ),
                sample_size = 56,
                store_results = True,
                include_members = True,
                compute_metrics = True,
                save_artifacts = True
            )
        else:
            return ExecuteClusterRequest(
                collection_ids = [
                    ''
                    ],
                config = mixpeek.models.clustering_config.ClusteringConfig(
                    algorithm = 'kmeans', 
                    algorithm_params = null, 
                    feature_vector = mixpeek.models.feature_vector_ref.FeatureVectorRef(
                        feature_address = mixpeek.models.feature_address.FeatureAddress(
                            scheme = 'mixpeek', 
                            extractor = '', 
                            version = '', 
                            output = '', ), ), 
                    additional_features = [
                        ''
                        ], 
                    normalize_features = True, 
                    dimensionality_reduction = null, 
                    hierarchical = True, 
                    max_hierarchy_depth = 56, 
                    llm_labeling = mixpeek.models.llm_labeling.LLMLabeling(
                        enabled = True, 
                        provider = 'openai', 
                        model_name = '', 
                        include_summary = True, 
                        include_keywords = True, 
                        max_samples_per_cluster = 56, 
                        custom_prompt = '', 
                        parameters = { }, ), 
                    batch_size = 56, 
                    parallelism = 56, 
                    sample_size = 56, ),
        )
        """

    def testExecuteClusterRequest(self):
        """Test ExecuteClusterRequest"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()

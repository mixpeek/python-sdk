# BatchModel

Model representing a batch of objects for processing through collections.  A batch groups bucket objects together for processing through one or more collections. Batches support multi-tier processing where collections are processed in dependency order (e.g., bucket → chunks → frames → scenes). Each tier has independent task tracking.  Use Cases:     - Process multiple objects through collections in a single batch     - Track progress of multi-tier decomposition pipelines     - Monitor and retry individual processing tiers     - Query batch status and tier-specific task information  Lifecycle:     1. Created in DRAFT status with object_ids     2. Submitted for processing → status changes to PENDING     3. Each tier processes sequentially (tier 0 → tier 1 → ... → tier N)     4. Batch completes when all tiers finish (status=COMPLETED) or any tier fails (status=FAILED)  Multi-Tier Processing:     - Tier 0: Bucket objects → Collections (bucket as source)     - Tier N (N > 0): Collection documents → Collections (upstream collection as source)     - Each tier gets independent task tracking via tier_tasks array     - Processing proceeds tier-by-tier with automatic chaining  Requirements:     - batch_id: OPTIONAL (auto-generated if not provided)     - bucket_id: REQUIRED     - status: OPTIONAL (defaults to DRAFT)     - object_ids: REQUIRED for processing (must have at least 1 object)     - collection_ids: OPTIONAL (discovered via DAG resolution)     - tier_tasks: OPTIONAL (populated during processing)     - current_tier: OPTIONAL (set during processing)     - total_tiers: OPTIONAL (defaults to 1, set during DAG resolution)     - dag_tiers: OPTIONAL (populated during DAG resolution)

## Properties

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**batch_id** | **str** | OPTIONAL (auto-generated if not provided). Unique identifier for this batch. Format: &#39;btch_&#39; prefix followed by 12-character secure token. Generated using generate_secure_token() from shared.utilities.helpers. Used to query batch status and track processing across tiers. Immutable after creation. | [optional] 
**bucket_id** | **str** | REQUIRED. Unique identifier of the bucket containing the objects to process. Must be a valid bucket ID that exists in the system. All object_ids must belong to this bucket. Format: Bucket ID as defined when bucket was created. | 
**status** | [**TaskStatusEnum**](TaskStatusEnum.md) | OPTIONAL (defaults to DRAFT). Current processing status of the batch. Lifecycle: DRAFT → PENDING → IN_PROGRESS → COMPLETED/FAILED. DRAFT: Batch created but not yet submitted. PENDING: Batch submitted and queued for processing. IN_PROGRESS: Batch currently processing (one or more tiers active). COMPLETED: All tiers successfully completed. FAILED: One or more tiers failed. Aggregated from tier_tasks statuses during multi-tier processing. | [optional] 
**object_ids** | **List[str]** | REQUIRED for processing (must have at least 1). List of object IDs to include in this batch. All objects must exist in the specified bucket_id. These objects are the source data for tier 0 processing. Minimum 1 object, no maximum limit. Objects are processed in parallel within each tier. | [optional] 
**collection_ids** | **List[str]** | OPTIONAL. List of all collection IDs involved in this batch&#39;s processing. Automatically populated during DAG resolution from dag_tiers. Includes collections from all tiers (flattened view of dag_tiers). Used for quick lookups without traversing tier structure. Format: List of collection IDs across all tiers. | [optional] 
**error** | **str** | OPTIONAL. Legacy error message field for backward compatibility. None if batch succeeded or is still processing. Contains human-readable error description from first failed tier. DEPRECATED: Use tier_tasks[].errors for detailed error information. For multi-tier batches, typically contains the error from the first failed tier. Check tier_tasks array for tier-specific error details and error_summary for aggregation. | [optional] 
**error_summary** | **Dict[str, int]** | OPTIONAL. Aggregated summary of errors across ALL tiers in the batch. None if batch succeeded or is still processing. Maps error_type (category) to total count of affected documents across all tiers. Provides quick batch-wide overview of error distribution. Example: {&#39;dependency&#39;: 15, &#39;authentication&#39;: 25, &#39;validation&#39;: 5} means across all tiers, 15 documents failed with dependency errors, 25 with auth errors, 5 with validation errors. Automatically aggregated from tier_tasks[].error_summary. Used for batch health dashboard and error trend analysis. | [optional] 
**type** | [**BatchType**](BatchType.md) | OPTIONAL (defaults to BUCKET). Type of batch. BUCKET: Standard batch processing bucket objects through collections. COLLECTION: Reserved for future collection-only batch processing. Currently only BUCKET type is supported. | [optional] 
**manifest_key** | **str** | OPTIONAL. S3 key where the batch manifest is stored. Contains metadata and row data (Parquet) for Engine processing. For tier 0, points to bucket object manifest. For tier N+, points to collection document manifest. Format: S3 path (e.g., &#39;namespace_id/internal_id/manifests/tier_0.parquet&#39;). Generated during batch submission. | [optional] 
**task_id** | **str** | OPTIONAL. Primary task ID for the batch (typically tier 0 task). Used for backward compatibility with single-tier batch tracking. For multi-tier batches, prefer querying tier_tasks array for granular tracking. Format: Task ID as generated for tier 0. | [optional] 
**loaded_object_ids** | **List[str]** | OPTIONAL. List of object IDs that were successfully validated and loaded into the batch. Subset of object_ids that passed validation. Used to track which objects are ready for processing. None if batch hasn&#39;t been validated yet. | [optional] 
**internal_metadata** | **object** | OPTIONAL. Internal engine/job metadata for system use. May contain: job_id (provider-specific), engine_version, processing hints, last_health_check. last_health_check: Most recent health check results with health_status, enriched_documents, vector_populated_count, stall_duration_seconds, recommendations, missing_features. Populated asynchronously via Celery task (non-blocking, best-effort). Used for troubleshooting batch processing issues via API. NOTE: In MongoDB, this is stored under &#39;_internal.processing&#39; path. | [optional] 
**metadata** | **object** | OPTIONAL. User-defined metadata for the batch. Arbitrary key-value pairs for user tracking and organization. Persisted with the batch and returned in API responses. Not used by the system for processing logic. Examples: campaign_id, user_email, processing_notes. | [optional] 
**tier_tasks** | [**List[TierTaskInfo]**](TierTaskInfo.md) | OPTIONAL. List of tier task tracking information for multi-tier processing. Each element represents one tier in the processing pipeline. Empty array for simple single-tier batches. Populated during batch submission with tier 0 info, then appended as tiers progress. Each TierTaskInfo contains: tier_num, task_id, status, collection_ids, timestamps. Used for granular monitoring: &#39;Show me status of tier 2&#39; or &#39;Retry tier 1&#39;. Array index typically matches tier_num (tier_tasks[0] &#x3D; tier 0, tier_tasks[1] &#x3D; tier 1, etc.). | [optional] 
**current_tier** | **int** | OPTIONAL. Zero-based index of the currently processing tier. None if batch hasn&#39;t started processing (status&#x3D;DRAFT or PENDING). Updated as batch progresses through tiers. Used to show processing progress: &#39;Processing tier 2 of 5&#39;. Set to last tier number when batch completes. Example: If processing tier 1 (frames), current_tier&#x3D;1. | [optional] 
**total_tiers** | **int** | OPTIONAL (defaults to 1). Total number of tiers in the collection DAG. Minimum 1 (tier 0 only &#x3D; bucket → collection). Set during DAG resolution when batch is submitted. Equals len(dag_tiers) if dag_tiers is populated. Used to calculate progress: current_tier / total_tiers. Example: 5-tier pipeline (bucket → chunks → frames → scenes → summaries) has total_tiers&#x3D;5. | [optional] [default to 1]
**dag_tiers** | **List[List[str]]** | OPTIONAL. Complete DAG tier structure for this batch. List of tiers, where each tier is a list of collection IDs to process at that stage. Tier 0 &#x3D; bucket-sourced collections. Tier N (N &gt; 0) &#x3D; collection-sourced collections. Collections within same tier have no dependencies (can run in parallel). Collections in tier N+1 depend on collections in tier N. Populated during DAG resolution at batch submission. Used for tier-by-tier processing orchestration. Example: [[&#39;col_chunks&#39;], [&#39;col_frames&#39;, &#39;col_objects&#39;], [&#39;col_scenes&#39;]] &#x3D; 3 tiers where frames and objects run in parallel at tier 1. | [optional] 
**created_at** | **datetime** | OPTIONAL (auto-set on creation). ISO 8601 timestamp when batch was created. Set using current_time() from shared.utilities.helpers. Immutable after creation. Used for batch age tracking and cleanup of old batches. | [optional] 
**updated_at** | **datetime** | OPTIONAL (auto-updated). ISO 8601 timestamp when batch was last modified. Updated using current_time() whenever batch status or tier_tasks change. Used to track batch activity and identify stale batches. | [optional] 

## Example

```python
from mixpeek.models.batch_model import BatchModel

# TODO update the JSON string below
json = "{}"
# create an instance of BatchModel from a JSON string
batch_model_instance = BatchModel.from_json(json)
# print the JSON string representation of the object
print(BatchModel.to_json())

# convert the object into a dict
batch_model_dict = batch_model_instance.to_dict()
# create an instance of BatchModel from a dict
batch_model_from_dict = BatchModel.from_dict(batch_model_dict)
```
[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)


